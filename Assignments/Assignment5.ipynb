{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/connordouglas10/DS-Tech-2025January/blob/main/Assignments/Assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKaSofEz2CPl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#If opening in colab run this cell\n",
    "!git clone https://github.com/connordouglas10/DS-Tech-2025January.git\n",
    "%cd DS-Tech-2025January/Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJGEq5z12CPn"
   },
   "source": [
    "# IF OPENING IN COLAB, REMEMBER TO SAVE THIS NOTEBOOK TO GOOGLE DRIVE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvaRhyux2CPs"
   },
   "source": [
    "# Predicting Customer Complaints\n",
    "\n",
    "Our problem setting is similar that which we saw in class. You've been hired by Trans American Airlines (TAA) as a data science consultant. Your job is to identify customer service issues in tweets, so the issues can be directed to the customer experience team.\n",
    "\n",
    "We will be trying a variety of text representation techniques and modeling approaches to see which work the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we will be using\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QxorapP2CPt"
   },
   "source": [
    "__1. Load the data. Print a portion of the DataFrame.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "fJnv3sWZ2CPt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# If necessary change the path below so that it points to your file.\n",
    "data_path = \"./data/data-hw4.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Define a binary target variable for \"Customer Service Issue\". Keep only this binary target variable and the text in the DataFrame. What portion of tweets are about a customer service issue?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmcmkCD-2CPu"
   },
   "source": [
    "__3. To make things technically easier, we will not do cross-validation on this assignment. Instead, split the data into 80% training data, 20% test data. Then, split the train set into 80% train, 20% validation data.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "mx5P6XMn2CPu"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Create and train a binary vector representation along with a TF-IDF representation of the words in each tweet. Then, use apply these vectorizors to create two representations of the training and validation set.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_vectorizer = CountVectorizer(binary=True)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd1LLyU_2CPv"
   },
   "source": [
    "__5. Build 2 logistic regression models, one for each representation. For each of these, try different values for the hyperparameter C.__\n",
    "\n",
    "_Try to optimize generalization performance, evaluated based on ROC Area on the validation set. Try looping over values of C for each model; in this loop train and evaluate + print the AUC. Report the best hyperparameter you found for the model for each representation (binary and TFIDF). Pick one model to move forward with for each representation Why did you select this one?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "f4xmajqV2CPw"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9MWzvGh2CPy"
   },
   "source": [
    "__6. We will now try using a transformer embedding representations of text. This helps to capture the sequential dependencies of the text. The SentenceTransformers library enables easy embedding representations. Embed the training, validation, and test sets and store under a new variable name. We've started you with the training set. Print the dimensionality of the embeddings (using X_train_embeddings.shape[1]).__\n",
    "\n",
    "This might take a bit of time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary library\n",
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SentenceTransformer class\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained SentenceTransformer model\n",
    "# You can choose a model like 'all-MiniLM-L6-v2', 'paraphrase-MiniLM-L3-v2', etc.\n",
    "model_name = 'all-MiniLM-L6-v2' \n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Compute embeddings for the training set with model.encode\n",
    "X_train_embeddings = model.encode(X_train.to_numpy())\n",
    "\n",
    "# Display the embeddings\n",
    "print(\"Embeddings shape:\", X_train_embeddings.shape)\n",
    "print(\"Example embedding for the first sentence:\", X_train_embeddings[0])\n",
    "\n",
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7. Build a logistic regression model using this new embedding representation as the features. Try different values for the hyperparameter C.__\n",
    "\n",
    "Try to optimize generalization performance, evaluated based on ROC Area on the validation set. Report the best hyperparameter you found. Pick one model to move forward with. Why did you select this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5QTooX42CPx"
   },
   "source": [
    "__8. Now, we will do a similar process for training a neural network. Try two other set-ups, then train and evaluate each set-up on the validation set. Try adding a layer, changing the width of internal (hidden) layers (i.e. not input or output layers), or changing the number of epochs. Report the AUC of each set-up.__\n",
    "\n",
    "__HINT: There is an example below of one architecture. Evaluate this performance with AUC on the validation set, then repeat this two more times with different network shapes.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AqOpFxp2CPx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Example input size (number of features from X_train_embeddings.shape[0])\n",
    "input_size = X_train_embeddings.shape[1]  # Replace with your actual input dimension\n",
    "\n",
    "# Define a simple neural network model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(input_size,)),  # Input layer\n",
    "    layers.Dense(128, activation='relu'),  # Hidden layer with ReLU activation\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model.fit(X_train_embeddings, y_train, epochs=10, validation_data=(X_val_embeddings, y_val))\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__9. Display one ROC curve and AUC figures for the following on the validation set. Plot all curves on a single graph:__\n",
    "* The best logistic regression model using a binary representation\n",
    "* The best logistic regression model using a TF-IDF representation\n",
    "* The best logistic regression model using a SentenceTransformers embedding representation\n",
    "* The best neural network using a SentenceTransformers embedding representation\n",
    "\n",
    "You may need to copy code from various sections above to retrain each model on the best hyperparameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__10. Pick the best option from above, and graph the ROC curve with the AUC on our test set.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1tfHgSFzb29UlOp4fZg91RXOWby6_Vr6M",
     "timestamp": 1710185058102
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
