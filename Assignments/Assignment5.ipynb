{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/connordouglas10/DS-Tech-2025January/blob/main/Assignments/Assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKaSofEz2CPl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#If opening in colab run this cell\n",
    "!git clone https://github.com/connordouglas10/DS-Tech-2025January.git\n",
    "%cd DS-Tech-2025January/Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJGEq5z12CPn"
   },
   "source": [
    "# IF OPENING IN COLAB, REMEMBER TO SAVE THIS NOTEBOOK TO GOOGLE DRIVE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvaRhyux2CPs"
   },
   "source": [
    "# Predicting Customer Complaints\n",
    "\n",
    "Our problem setting is similar that which we saw in class. You've been hired by Trans American Airlines (TAA) as a data science consultant. Your job is to identify customer service issues in tweets, so the issues can be directed to the customer experience team.\n",
    "\n",
    "We will be trying a variety of text representation techniques and modeling approaches to see which work the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we will be using\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QxorapP2CPt"
   },
   "source": [
    "__1. Load the data. Print a portion of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "fJnv3sWZ2CPt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# If necessary change the path below so that it points to your file.\n",
    "data_path = \"./data/data-hw4.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Define a binary target variable for \"Customer Service Issue\". What portion of tweets are about a customer service issue?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmcmkCD-2CPu"
   },
   "source": [
    "__3. To make things technically easier, we will not do cross-validation on this assignment. Instead, split the data into 70% training data, 15% validation, and 15% test data.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "mx5P6XMn2CPu"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Create and train a binary vector representation along with a TF-IDF representation of the words in each tweet. Then, use apply these vectorizors to create two representations of the training set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_vectorizer = CountVectorizer(binary=True)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd1LLyU_2CPv"
   },
   "source": [
    "__5. Build 2 logistic regression models, one for each representation. For each of these, try different values for the hyperparameter C.__\n",
    "\n",
    "_Try to optimize generalization performance, evaluated based on ROC Area on the validation set. Report the best hyperparameter you found. Pick one model to move forward with. Why did you select this one?__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "f4xmajqV2CPw"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9MWzvGh2CPy"
   },
   "source": [
    "__6. We will now try using a transformer embedding representations of text. This helps to capture the sequential dependencies of the text. The SentenceTransformers library enables easy embedding representations. Embed the training, validation, and test sets and store under a new variable name. We've started you with the training set.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary library\n",
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SentenceTransformer class\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained SentenceTransformer model\n",
    "# You can choose a model like 'all-MiniLM-L6-v2', 'paraphrase-MiniLM-L3-v2', etc.\n",
    "model_name = 'all-MiniLM-L6-v2' \n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Compute embeddings for the training set\n",
    "X_train_embeddings = model.encode(X_train)\n",
    "\n",
    "# Display the embeddings\n",
    "print(\"Embeddings shape:\", X_train_embeddings.shape)\n",
    "print(\"Example embedding for the first sentence:\", X_train_embeddings[0])\n",
    "\n",
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7. Build a logistic regression model using this new embedding representation as the features. Try different values for the hyperparameter C.__\n",
    "\n",
    "Try to optimize generalization performance, evaluated based on ROC Area on the validation set. Report the best hyperparameter you found. Pick one model to move forward with. Why did you select this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5QTooX42CPx"
   },
   "source": [
    "__8. Now, we will do a similar process for training a neural network. Try another set-up, then train and evaluate that set-up on the validation set. Try adding a layer, changing the width of internal (hidden) layers (i.e. not input or output layers), or changing the number of epochs.__\n",
    "\n",
    "__HINT: There is an example below of one architecture. Evaluate this performance on the validation set, then repeat this two more times with different network shapes.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AqOpFxp2CPx"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Defining Keras Model\n",
    "kmodel = Sequential()\n",
    "kmodel.add(Dense(X_train_embeddings.shape[0],input_shape =(8,), activation = \"relu\"))\n",
    "kmodel.add(Dense(8,activation = \"relu\"))\n",
    "kmodel.add(Dense(1,activation = \"sigmoid\"))\n",
    "\n",
    "#Compile Keras Model\n",
    "kmodel.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics =['accuracy'])\n",
    "\n",
    "#Fitting Keras Model\n",
    "kmodel.fit(X_train,y_train,epochs = 10, batch_size = len(X_train))\n",
    "\n",
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__9. Display ROC curves and AUC figures for the following:__\n",
    "* The best logistic regression model using a binary representation\n",
    "* The best logistic regression model using a TF-IDF representation\n",
    "* The best logistic regression model using a SentenceTransformers embedding representation\n",
    "* The best neural network using a SentenceTransformers embedding representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__10. Pick the best option from above, and graph the ROC curve with the AUC on our test set.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1tfHgSFzb29UlOp4fZg91RXOWby6_Vr6M",
     "timestamp": 1710185058102
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
